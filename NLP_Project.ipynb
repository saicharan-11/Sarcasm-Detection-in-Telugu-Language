{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel(r\"D:\\NLP_telugu_data\\sarcastic_sentences.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Labels']=data['Labels'].replace(to_replace ='Normal question and sarcastic answer',value='Sarcastic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Labels']=data['Labels'].replace(to_replace ='Normal question and normal answer',value='Non-Sarcastic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>బంగారం ఆఫీస్ నుండి ఇప్పుడే వచ్చావా? లేదు గంట అ...</td>\n",
       "      <td>Sarcastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>డాక్టర్ నిన్ను నాన్వెజ్ మానేయమన్నారుగా ఇంకా మా...</td>\n",
       "      <td>Sarcastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>అల్లుడు? ఏంటి మావయ్య. నిన్ను అడగాలంటే కోద్ధిగా...</td>\n",
       "      <td>Sarcastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>నీతో మాట్లాడాలి, కొంచెం టైమ్ ఇస్తావా? అయ్యో నా...</td>\n",
       "      <td>Sarcastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>కెప్టెన్, టైటానిక్ షిప్ ఇంకా ఏం స్టార్ట్ చేయలే...</td>\n",
       "      <td>Sarcastic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences     Labels\n",
       "0  బంగారం ఆఫీస్ నుండి ఇప్పుడే వచ్చావా? లేదు గంట అ...  Sarcastic\n",
       "1  డాక్టర్ నిన్ను నాన్వెజ్ మానేయమన్నారుగా ఇంకా మా...  Sarcastic\n",
       "2  అల్లుడు? ఏంటి మావయ్య. నిన్ను అడగాలంటే కోద్ధిగా...  Sarcastic\n",
       "3  నీతో మాట్లాడాలి, కొంచెం టైమ్ ఇస్తావా? అయ్యో నా...  Sarcastic\n",
       "4  కెప్టెన్, టైటానిక్ షిప్ ఇంకా ఏం స్టార్ట్ చేయలే...  Sarcastic"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1791"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1332, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['Labels']=='Sarcastic'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(459, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['Labels']=='Non-Sarcastic'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Punctuation Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = '''!()-[]{};:'\"+\\,<>.?/@#$%^&*_~0123456789'''\n",
    "rpunct=[]\n",
    "for i in data.Sentences:\n",
    "    no_punct = \" \"\n",
    "    for i in i:\n",
    "        if i not in punctuations:\n",
    "            no_punct=no_punct+i\n",
    "    rpunct.append(no_punct.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'బంగారం ఆఫీస్ నుండి ఇప్పుడే వచ్చావా లేదు గంట అయ్యింది బస్ స్టాండులో జామకాయలు అమ్మి వచ్చేటప్పటికి ఈ టైమ్ అయ్యింది'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpunct[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1791"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rpunct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=[]\n",
    "for i in rpunct:\n",
    "    g=i.split()\n",
    "    tokens.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['బంగారం',\n",
       " 'ఆఫీస్',\n",
       " 'నుండి',\n",
       " 'ఇప్పుడే',\n",
       " 'వచ్చావా',\n",
       " 'లేదు',\n",
       " 'గంట',\n",
       " 'అయ్యింది',\n",
       " 'బస్',\n",
       " 'స్టాండులో',\n",
       " 'జామకాయలు',\n",
       " 'అమ్మి',\n",
       " 'వచ్చేటప్పటికి',\n",
       " 'ఈ',\n",
       " 'టైమ్',\n",
       " 'అయ్యింది']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=open(r\"D:\\NLP_telugu_data\\telugu_stop_words.txt\",'r',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_list=[]\n",
    "for i in stop_words.readlines():\n",
    "    stop_words_list.append(i.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ప్రకారం',\n",
       " 'అనుగుణంగా',\n",
       " 'అడ్డంగా',\n",
       " 'నిజంగా',\n",
       " 'తర్వాత',\n",
       " 'మళ్ళీ',\n",
       " 'వ్యతిరేకంగా',\n",
       " 'అందరూ',\n",
       " 'దాదాపు',\n",
       " 'వెంట',\n",
       " 'ఇప్పటికే',\n",
       " 'కూడా',\n",
       " 'అయితే',\n",
       " 'ఎప్పుడు',\n",
       " 'వద్ద',\n",
       " 'మధ్య',\n",
       " 'ఒక',\n",
       " 'మరియు']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words_list[2:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tokens:\n",
    "    for j in i:\n",
    "        if j in stop_words_list:\n",
    "            i.remove(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['బంగారం',\n",
       " 'ఆఫీస్',\n",
       " 'నుండి',\n",
       " 'ఇప్పుడే',\n",
       " 'వచ్చావా',\n",
       " 'లేదు',\n",
       " 'గంట',\n",
       " 'అయ్యింది',\n",
       " 'బస్',\n",
       " 'స్టాండులో',\n",
       " 'జామకాయలు',\n",
       " 'అమ్మి',\n",
       " 'వచ్చేటప్పటికి',\n",
       " 'టైమ్',\n",
       " 'అయ్యింది']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, inspect\n",
    "import importlib\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "grandparent_dir = os.path.dirname(parent_dir)\n",
    "lib_dir = r'D:\\NLP_telugu_data\\telugu_nlp-master\\lib\\lang_tools_te\\bin'\n",
    "sys.path.insert(1,lib_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lemmatiser as lmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_tmp_file_name=r\"D:\\NLP_telugu_data\\telugu_words_1.txt\"\n",
    "tagger_op_file=r\"D:\\NLP_telugu_data\\tagger_out.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger_file_path=r\"D:\\NLP_telugu_data\\telugu_nlp-master\\lib\\lang_tools_te\\bin\\tnt\"\n",
    "models_path=r\"D:\\NLP_telugu_data\\telugu_nlp-master\\lib\\lang_tools_te\\models\\telugu\"\n",
    "lang_tools_path=r\"D:\\NLP_telugu_data\\telugu_nlp-master\\lib\\lang_tools_te\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_tmp_file(te_list):\n",
    "    with open(words_tmp_file_name, 'w',encoding='utf-8') as file:\n",
    "        for item in te_list:\n",
    "            file.write(item +'\\n')\n",
    "    file.close()\n",
    "    return\n",
    "\n",
    "def run_tagger_script():\n",
    "    os.system(tagger_file_path + \" -H -v0 \"+ models_path + \" \" + words_tmp_file_name + \n",
    "              \" | sed -e 's/\\t\\+/\\t/g' > \" + tagger_op_file)\n",
    "    \n",
    "    return\n",
    "\n",
    "def read_tagger_output():\n",
    "    texts_list = []\n",
    "    \n",
    "    with open(tagger_op_file, 'r',encoding='utf-8') as file:\n",
    "        for line in file.readlines():\n",
    "            texts_list.append(line)\n",
    "            \n",
    "        texts_list.pop()\n",
    "            \n",
    "    return texts_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_string = 'బంగారం ఆఫీస్ నుండి ఇప్పుడే వచ్చావా లేదు గంట అయ్యింది బస్ స్టాండులో జామకాయలు అమ్మి వచ్చేటప్పటికి ఈ టైమ్ అయ్యింది'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_tagger_script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\NLP_telugu_data\\telugu_nlp-master\\lib\\lang_tools_te\\bin\\tnt -H -v0 D:\\NLP_telugu_data\\telugu_nlp-master\\lib\\lang_tools_te\\models\\telugu D:\\NLP_telugu_data\\telugu_words_1.txt | sed -e 's/\t\\+/\t/g' > D:\\NLP_telugu_data\\tagger_out.txt\n"
     ]
    }
   ],
   "source": [
    "print(tagger_file_path + \" -H -v0 \"+ models_path + \" \" + words_tmp_file_name + \n",
    "              \" | sed -e 's/\\t\\+/\\t/g' > \" + tagger_op_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_list=te_string.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['బంగారం',\n",
       " 'ఆఫీస్',\n",
       " 'నుండి',\n",
       " 'ఇప్పుడే',\n",
       " 'వచ్చావా',\n",
       " 'లేదు',\n",
       " 'గంట',\n",
       " 'అయ్యింది',\n",
       " 'బస్',\n",
       " 'స్టాండులో',\n",
       " 'జామకాయలు',\n",
       " 'అమ్మి',\n",
       " 'వచ్చేటప్పటికి',\n",
       " 'ఈ',\n",
       " 'టైమ్',\n",
       " 'అయ్యింది']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_tmp_file(te_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_tagger_script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "postags = pd.read_pickle(r'D:\\NLP_telugu_data\\postags.pkl')\n",
    "tokens = pd.read_pickle(r'D:\\NLP_telugu_data\\tokens.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sremoved_sentences=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tokens:\n",
    "    st=' '.join(i)\n",
    "    sremoved_sentences.append(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1791, 1791)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(postags),len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIFIDF VECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(sremoved_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['అడగల',\n",
       " 'అడవ',\n",
       " 'అణ',\n",
       " 'అత',\n",
       " 'అతడ',\n",
       " 'అతన',\n",
       " 'అద',\n",
       " 'అదన',\n",
       " 'అధ',\n",
       " 'అన',\n",
       " 'అనక',\n",
       " 'అనట',\n",
       " 'అనడ',\n",
       " 'అనద',\n",
       " 'అనర',\n",
       " 'అనల',\n",
       " 'అనవ',\n",
       " 'అప',\n",
       " 'అఫ',\n",
       " 'అబ',\n",
       " 'అబద',\n",
       " 'అభ',\n",
       " 'అమ',\n",
       " 'అమర',\n",
       " 'అయ',\n",
       " 'అయన',\n",
       " 'అయస',\n",
       " 'అర',\n",
       " 'అరక',\n",
       " 'అరగక']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[20:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[]\n",
    "for i in data['Labels']:\n",
    "    if i=='Sarcastic':\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'D:\\NLP_telugu_data\\y.pkl', 'wb') as f:\n",
    "    pickle.dump(y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "naive_model=GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_model.fit(X_train.toarray(),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=naive_model.predict(X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.520891364902507"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model=SVC(C=0.1,kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_y_pred=svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.766016713091922"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(svm_y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model=MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pinup\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_pred=MLP_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7827298050139275"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(MLP_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model1=RandomForestClassifier()\n",
    "rf_model1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred1=rf_model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8272980501392758"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(rf_pred1,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sent=[]\n",
    "for i in postags:\n",
    "    st=\" \".join(i)\n",
    "    pos_sent.append(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Tokens']=sremoved_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['postags']=pos_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>postags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>బంగారం ఆఫీస్ నుండి ఇప్పుడే వచ్చావా? లేదు గంట అ...</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>బంగారం ఆఫీస్ నుండి ఇప్పుడే వచ్చావా లేదు గంట అయ...</td>\n",
       "      <td>NN NN PSP NST VM VM NN VM NN NN NN VM NST NN VM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>డాక్టర్ నిన్ను నాన్వెజ్ మానేయమన్నారుగా ఇంకా మా...</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>డాక్టర్ నిన్ను నాన్వెజ్ మానేయమన్నారుగా ఇంకా మా...</td>\n",
       "      <td>NN PRP NN RB INTF VM INJ WQ VM NN NN NNP NN VM RP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>అల్లుడు? ఏంటి మావయ్య. నిన్ను అడగాలంటే కోద్ధిగా...</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>అల్లుడు ఏంటి మావయ్య నిన్ను అడగాలంటే కోద్ధిగా ఇ...</td>\n",
       "      <td>NN WQ NN PRP VM RB RB VM INJ NST NN VM NN VM V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>నీతో మాట్లాడాలి, కొంచెం టైమ్ ఇస్తావా? అయ్యో నా...</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>నీతో మాట్లాడాలి కొంచెం టైమ్ ఇస్తావా అయ్యో వాచ్...</td>\n",
       "      <td>PRP VM QF NN VM INJ NN NN VM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>కెప్టెన్, టైటానిక్ షిప్ ఇంకా ఏం స్టార్ట్ చేయలే...</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>కెప్టెన్ టైటానిక్ షిప్ ఇంకా ఏం స్టార్ట్ చేయలేద...</td>\n",
       "      <td>NNP NN NN INTF WQ NN VM NN PRP NN PSP VM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences     Labels  \\\n",
       "0  బంగారం ఆఫీస్ నుండి ఇప్పుడే వచ్చావా? లేదు గంట అ...  Sarcastic   \n",
       "1  డాక్టర్ నిన్ను నాన్వెజ్ మానేయమన్నారుగా ఇంకా మా...  Sarcastic   \n",
       "2  అల్లుడు? ఏంటి మావయ్య. నిన్ను అడగాలంటే కోద్ధిగా...  Sarcastic   \n",
       "3  నీతో మాట్లాడాలి, కొంచెం టైమ్ ఇస్తావా? అయ్యో నా...  Sarcastic   \n",
       "4  కెప్టెన్, టైటానిక్ షిప్ ఇంకా ఏం స్టార్ట్ చేయలే...  Sarcastic   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  బంగారం ఆఫీస్ నుండి ఇప్పుడే వచ్చావా లేదు గంట అయ...   \n",
       "1  డాక్టర్ నిన్ను నాన్వెజ్ మానేయమన్నారుగా ఇంకా మా...   \n",
       "2  అల్లుడు ఏంటి మావయ్య నిన్ను అడగాలంటే కోద్ధిగా ఇ...   \n",
       "3  నీతో మాట్లాడాలి కొంచెం టైమ్ ఇస్తావా అయ్యో వాచ్...   \n",
       "4  కెప్టెన్ టైటానిక్ షిప్ ఇంకా ఏం స్టార్ట్ చేయలేద...   \n",
       "\n",
       "                                             postags  \n",
       "0    NN NN PSP NST VM VM NN VM NN NN NN VM NST NN VM  \n",
       "1  NN PRP NN RB INTF VM INJ WQ VM NN NN NNP NN VM RP  \n",
       "2  NN WQ NN PRP VM RB RB VM INJ NST NN VM NN VM V...  \n",
       "3                       PRP VM QF NN VM INJ NN NN VM  \n",
       "4           NNP NN NN INTF WQ NN VM NN PRP NN PSP VM  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1,X_test1,y_train1,y_test1=train_test_split(data[['Tokens','postags']],y,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "pos_X = vectorizer.fit_transform(pos_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "e=TfidfVectorizer()\n",
    "e1=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer(\n",
    "    [('tfidf1', e, 'Tokens'), \n",
    "    ('tfidf2', e1, 'postags')],\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model1=SVC(C=0.1,kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('tfidf1', TfidfVectorizer(),\n",
       "                                                  'Tokens'),\n",
       "                                                 ('tfidf2', TfidfVectorizer(),\n",
       "                                                  'postags')])),\n",
       "                ('classify', SVC(C=0.1))])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "                  ('tfidf', column_transformer),\n",
    "                  ('classify', svm_model1)\n",
    "                ])\n",
    "pipe.fit(X_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_pred=pipe.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7520891364902507"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pos_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('tfidf1', TfidfVectorizer(),\n",
       "                                                  'Tokens'),\n",
       "                                                 ('tfidf2', TfidfVectorizer(),\n",
       "                                                  'postags')])),\n",
       "                ('classify', RandomForestClassifier())])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1 = Pipeline([\n",
    "                  ('tfidf', column_transformer),\n",
    "                  ('classify', rf_model)\n",
    "                ])\n",
    "pipe1.fit(X_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('tfidf1', TfidfVectorizer(),\n",
       "                                                  'Tokens'),\n",
       "                                                 ('tfidf2', TfidfVectorizer(),\n",
       "                                                  'postags')])),\n",
       "                ('classify', RandomForestClassifier())])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1.fit(X_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred=pipe.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8662952646239555"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(rf_pred,y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model1=MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('tfidf1', TfidfVectorizer(),\n",
       "                                                  'Tokens'),\n",
       "                                                 ('tfidf2', TfidfVectorizer(),\n",
       "                                                  'postags')])),\n",
       "                ('classify', RandomForestClassifier())])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2 = Pipeline([\n",
    "                  ('tfidf', column_transformer),\n",
    "                  ('classify', rf_model)\n",
    "                ])\n",
    "pipe2.fit(X_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_pred1=pipe2.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8495821727019499"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(mlp_pred1,y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRI-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=TfidfVectorizer(ngram_range=(3,3),token_pattern=r'\\S+')\n",
    "t1=TfidfVectorizer(ngram_range=(3,3),token_pattern=r'\\S+')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer1 = ColumnTransformer(\n",
    "    [('tfidf1', t, 'Tokens'), \n",
    "    ('tfidf2', t1, 'postags')],\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('tfidf1',\n",
       "                                                  TfidfVectorizer(ngram_range=(3,\n",
       "                                                                               3)),\n",
       "                                                  'Tokens'),\n",
       "                                                 ('tfidf2',\n",
       "                                                  TfidfVectorizer(ngram_range=(3,\n",
       "                                                                               3)),\n",
       "                                                  'postags')])),\n",
       "                ('classify', RandomForestClassifier())])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipetri = Pipeline([\n",
    "                  ('tfidf', column_transformer1),\n",
    "                  ('classify', rf_model)\n",
    "                ])\n",
    "pipetri.fit(X_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_rf_pred=pipetri.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8635097493036211"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(tri_rf_pred,y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('tfidf1',\n",
       "                                                  TfidfVectorizer(ngram_range=(3,\n",
       "                                                                               3)),\n",
       "                                                  'Tokens'),\n",
       "                                                 ('tfidf2',\n",
       "                                                  TfidfVectorizer(ngram_range=(3,\n",
       "                                                                               3)),\n",
       "                                                  'postags')])),\n",
       "                ('classify', SVC(C=0.1))])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipetri1 = Pipeline([\n",
    "                  ('tfidf', column_transformer1),\n",
    "                  ('classify', svm_model)\n",
    "                ])\n",
    "pipetri1.fit(X_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_svm_pred=pipetri1.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7437325905292479"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(tri_svm_pred,y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model=MLPClassifier(activation='logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('tfidf1',\n",
       "                                                  TfidfVectorizer(ngram_range=(3,\n",
       "                                                                               3),\n",
       "                                                                  token_pattern='\\\\S+'),\n",
       "                                                  'Tokens'),\n",
       "                                                 ('tfidf2',\n",
       "                                                  TfidfVectorizer(ngram_range=(3,\n",
       "                                                                               3),\n",
       "                                                                  token_pattern='\\\\S+'),\n",
       "                                                  'postags')])),\n",
       "                ('classify', MLPClassifier(activation='logistic'))])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipetri2 = Pipeline([\n",
    "                  ('tfidf', column_transformer1),\n",
    "                  ('classify', mlp_model)\n",
    "                ])\n",
    "pipetri2.fit(X_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pipetri2.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7353760445682451"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred,y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=TfidfVectorizer(ngram_range=(3,3),token_pattern=r'\\S+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "O=t.fit_transform(sremoved_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1791, 20975)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
